{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jorgenv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"bert-base-cased\",\n",
    "        split='train'\n",
    "    ):\n",
    "        self._device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        # self._config = BertConfig.from_pretrained(model_name)\n",
    "        # self._bert_model = BertModel.from_pretrained(model_name, config=self._config)\n",
    "        # self._bert_model.eval()\n",
    "        # self._bert_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "        self._bert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        self._data_df = pd.read_csv(f\"../data/{split}_data.csv\", index_col=\"Date\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data_df.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._data_df.iloc[index]\n",
    "        label = row[-1]\n",
    "        text_series = row[:-3]\n",
    "        nan_count = text_series.isna().sum()\n",
    "        day_text_matrix = np.empty((text_series.size - nan_count, 768))\n",
    "        # self._bert_model = self._bert_model.to(self._device)\n",
    "        for index, text in enumerate(text_series):\n",
    "            if isinstance(text, str):\n",
    "                # tokens = self._bert_tokenizer(text, return_tensors='pt')\n",
    "                # output = self._bert_model(tokens.input_ids.to(self._device))\n",
    "                # latent_matrix = output.last_hidden_state[0]\n",
    "                # mean_vector = torch.mean(latent_matrix, 0)\n",
    "                # mean_vector = mean_vector.to('cpu').detach().numpy()\n",
    "                # mean_vector = mean_vector.reshape((1,-1))\n",
    "                # day_text_matrix[index, :] = mean_vector\n",
    "                sentences = [text]\n",
    "                sentence_embeddings = self._bert_model.encode(sentences)\n",
    "                day_text_matrix[index, :] = sentence_embeddings[0]\n",
    "        return (\n",
    "            torch.tensor(day_text_matrix),\n",
    "            torch.tensor(label)\n",
    "        )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 768\n",
    "        self.num_layers = 1\n",
    "        self._device = device\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.7,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x.size(0))\n",
    "        output, state = self.lstm(x, (h0, c0))\n",
    "        print(output.size())\n",
    "        print(\"-\"*20)\n",
    "        for item in state:\n",
    "            print(item.size())\n",
    "        print(\"=\"*40)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        output = torch.sigmoid(output)\n",
    "        return output, state\n",
    "\n",
    "    def init_hidden(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self._device),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self._device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(train_dataset, val_dataset, model, device, batch_size=32, max_epochs=1):\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    results = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"val_accuracy\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        results[\"epoch\"].append(epoch)\n",
    "\n",
    "        train_running_loss = []\n",
    "        train_running_accuracy = []\n",
    "\n",
    "        model = model.train()\n",
    "        for _, (x, y_true) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            y_pred, _ = model(x.float())\n",
    "            y_true = y_true.reshape((-1, 1))\n",
    "            loss = criterion(y_pred, y_true.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss.append(loss.item())\n",
    "\n",
    "            pred = np.round(y_pred.cpu().detach())\n",
    "            target = np.round(y_true.cpu().detach())\n",
    "            accuracy = accuracy_score(target, pred)\n",
    "            train_running_accuracy.append(accuracy)\n",
    "\n",
    "        train_loss = np.mean(train_running_loss)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        train_accuracy = np.mean(train_running_accuracy)\n",
    "        results[\"train_accuracy\"].append(train_accuracy)\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        val_running_accuracy = []\n",
    "\n",
    "        model = model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for _, (x, y_true) in enumerate(val_dataloader):\n",
    "                x = x.to(device)\n",
    "                y_true = y_true.to(device)\n",
    "                y_pred, _ = model(x.float())\n",
    "                y_true = y_true.reshape((-1, 1))\n",
    "\n",
    "                pred = np.round(y_pred.cpu().detach())\n",
    "                target = np.round(y_true.cpu().detach())\n",
    "                accuracy = accuracy_score(target, pred)\n",
    "                val_running_accuracy.append(accuracy)\n",
    "        \n",
    "        val_accuracy = np.mean(val_running_accuracy)\n",
    "        results[\"val_accuracy\"].append(val_accuracy)\n",
    "        print({ 'epoch': epoch, 'train_loss': train_loss, 'train_accuracy': train_accuracy, 'val_accuracy': val_accuracy })\n",
    "\n",
    "    return results\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n",
      "torch.Size([32, 25, 768])\n",
      "--------------------\n",
      "torch.Size([1, 32, 768])\n",
      "torch.Size([1, 32, 768])\n",
      "========================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m Model(device)\n\u001b[0;32m----> 6\u001b[0m results \u001b[39m=\u001b[39m train(train_dataset, val_dataset, model, device)\n",
      "\u001b[1;32m/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb Cell 4'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, val_dataset, model, device, batch_size, max_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000005vscode-remote?line=28'>29</a>\u001b[0m train_running_accuracy \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000005vscode-remote?line=30'>31</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000005vscode-remote?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, (x, y_true) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000005vscode-remote?line=32'>33</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000005vscode-remote?line=33'>34</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb Cell 2'\u001b[0m in \u001b[0;36mNewsDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=34'>35</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=35'>36</a>\u001b[0m         \u001b[39m# tokens = self._bert_tokenizer(text, return_tensors='pt')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=36'>37</a>\u001b[0m         \u001b[39m# output = self._bert_model(tokens.input_ids.to(self._device))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=40'>41</a>\u001b[0m         \u001b[39m# mean_vector = mean_vector.reshape((1,-1))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=41'>42</a>\u001b[0m         \u001b[39m# day_text_matrix[index, :] = mean_vector\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=42'>43</a>\u001b[0m         sentences \u001b[39m=\u001b[39m [text]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=43'>44</a>\u001b[0m         sentence_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bert_model\u001b[39m.\u001b[39;49mencode(sentences)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=44'>45</a>\u001b[0m         day_text_matrix[index, :] \u001b[39m=\u001b[39m sentence_embeddings[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=45'>46</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=46'>47</a>\u001b[0m     torch\u001b[39m.\u001b[39mtensor(day_text_matrix),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=47'>48</a>\u001b[0m     torch\u001b[39m.\u001b[39mtensor(label)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Code/UMBC_Capstone_2022/notebooks/modeling.ipynb#ch0000003vscode-remote?line=48'>49</a>\u001b[0m )\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:164\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=160'>161</a>\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=162'>163</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=163'>164</a>\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=165'>166</a>\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=166'>167</a>\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=63'>64</a>\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=65'>66</a>\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=66'>67</a>\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=68'>69</a>\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:554\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=551'>552</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=552'>553</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=553'>554</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=554'>555</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=555'>556</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=556'>557</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=557'>558</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=558'>559</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=559'>560</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=560'>561</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=561'>562</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=562'>563</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:340\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=336'>337</a>\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=337'>338</a>\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=339'>340</a>\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=340'>341</a>\u001b[0m     hidden_states,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=341'>342</a>\u001b[0m     attention_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=342'>343</a>\u001b[0m     head_mask[i],\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=343'>344</a>\u001b[0m     position_bias,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=344'>345</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=345'>346</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=346'>347</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=347'>348</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:299\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=289'>290</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=290'>291</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=291'>292</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=296'>297</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=297'>298</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=298'>299</a>\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=299'>300</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=300'>301</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=301'>302</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=302'>303</a>\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=303'>304</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=304'>305</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=305'>306</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=306'>307</a>\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:240\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=230'>231</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=231'>232</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=232'>233</a>\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=237'>238</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=238'>239</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=239'>240</a>\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=240'>241</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=241'>242</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=242'>243</a>\u001b[0m         head_mask,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=243'>244</a>\u001b[0m         position_bias,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=244'>245</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=245'>246</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=246'>247</a>\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(self_outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m hidden_states)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=247'>248</a>\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:171\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=167'>168</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk(hidden_states)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=168'>169</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(hidden_states)\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=170'>171</a>\u001b[0m q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose_for_scores(q)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=171'>172</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(k)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=172'>173</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(v)\n",
      "File \u001b[0;32m/mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:155\u001b[0m, in \u001b[0;36mMPNetSelfAttention.transpose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=152'>153</a>\u001b[0m new_x_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_attention_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_head_size)\n\u001b[1;32m    <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=153'>154</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mnew_x_shape)\n\u001b[0;32m--> <a href='file:///mnt/d/Code/UMBC_Capstone_2022/env/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = NewsDataset()\n",
    "val_dataset = NewsDataset(split='val')\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Model(device)\n",
    "\n",
    "results = train(train_dataset, val_dataset, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch', ylabel='value'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.drop(columns=[\"train_loss\"])\n",
    "sns.lineplot(x=\"epoch\", y=\"value\", hue=\"variable\", data=pd.melt(results_df, [\"epoch\"]))\n",
    "#plt.savefig('../plots/initial_train.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training binary classification model, try having a tanh activation function as output. The output would be tanh but use a function to transform to logits: \n",
    "\n",
    "https://stats.stackexchange.com/a/221905\n",
    "https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python/36440463#36440463"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8815d38e2f44888bf9d2d27291709bfd1a05b28bf990b1e1d952750508868489"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
