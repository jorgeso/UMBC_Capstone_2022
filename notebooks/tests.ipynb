{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7fb221824f70>\n",
      "1\n",
      "NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb221b58f50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.5525,  0.6355, -0.3968]]),\n",
       " tensor([[-0.6571, -1.6428,  0.9803]]),\n",
       " tensor([[-0.0421, -0.8206,  0.3133]]),\n",
       " tensor([[-1.1352,  0.3773, -0.2824]]),\n",
       " tensor([[-2.5667, -1.4303,  0.5009]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5438, -0.4057,  1.1341]]]),\n",
       " tensor([[[-1.1115,  0.3501, -0.7703]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5525,  0.6355, -0.3968]]])\n",
      "--------------------\n",
      "tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward0>)\n",
      "--------------------\n",
      "(tensor([[[-0.2682,  0.0304, -0.1526]]], grad_fn=<StackBackward0>), tensor([[[-1.0766,  0.0972, -0.5498]]], grad_fn=<StackBackward0>))\n",
      "==============================\n",
      "tensor([[[-0.6571, -1.6428,  0.9803]]])\n",
      "--------------------\n",
      "tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward0>)\n",
      "--------------------\n",
      "(tensor([[[-0.5370,  0.0346, -0.1958]]], grad_fn=<StackBackward0>), tensor([[[-1.1552,  0.1214, -0.2974]]], grad_fn=<StackBackward0>))\n",
      "==============================\n",
      "tensor([[[-0.0421, -0.8206,  0.3133]]])\n",
      "--------------------\n",
      "tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward0>)\n",
      "--------------------\n",
      "(tensor([[[-0.3947,  0.0391, -0.1217]]], grad_fn=<StackBackward0>), tensor([[[-1.0727,  0.1104, -0.2179]]], grad_fn=<StackBackward0>))\n",
      "==============================\n",
      "tensor([[[-1.1352,  0.3773, -0.2824]]])\n",
      "--------------------\n",
      "tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward0>)\n",
      "--------------------\n",
      "(tensor([[[-0.1854,  0.0740, -0.0979]]], grad_fn=<StackBackward0>), tensor([[[-1.0530,  0.1836, -0.1731]]], grad_fn=<StackBackward0>))\n",
      "==============================\n",
      "tensor([[[-2.5667, -1.4303,  0.5009]]])\n",
      "--------------------\n",
      "tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward0>)\n",
      "--------------------\n",
      "(tensor([[[-0.3600,  0.0893,  0.0215]]], grad_fn=<StackBackward0>), tensor([[[-1.1298,  0.4467,  0.0254]]], grad_fn=<StackBackward0>))\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    view = i.view(1, 1, -1)\n",
    "    print(view)\n",
    "    print(\"-\"*20)\n",
    "    out, hidden = lstm(view, hidden)\n",
    "    print(out)\n",
    "    print(\"-\"*20)\n",
    "    print(hidden)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1473,  0.3482,  1.1371]],\n",
      "\n",
      "        [[-0.3339, -1.4724,  0.7296]],\n",
      "\n",
      "        [[-0.1312, -0.6368,  1.0429]],\n",
      "\n",
      "        [[ 0.4903,  1.0318, -0.5989]],\n",
      "\n",
      "        [[ 1.6015, -1.0735, -1.2173]]])\n",
      "(tensor([[[ 0.6472, -0.0412, -0.1775]]]), tensor([[[-0.5000,  0.8673, -0.2732]]]))\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "    ):\n",
    "        self.args = args\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('../data/reddit-cleanjokes.csv')\n",
    "        text = train_df['Joke'].str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.args[\"sequence_length\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.args[\"sequence_length\"]]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.args[\"sequence_length\"]+1]),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  2,   8,   0, 248]), tensor([  8,   0, 248,  20]))\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(args={\n",
    "    \"max_epochs\": 10,\n",
    "    \"batch_size\": 256,\n",
    "    \"sequence_length\": 4\n",
    "})\n",
    "print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4159)\n",
      "tensor(1.0000)\n",
      "tensor(0.7311)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "scalar = torch.tensor(np.random.uniform(-10, 10))\n",
    "print(scalar)\n",
    "tanh = torch.nn.Tanh()\n",
    "t_scaled = tanh(scalar)\n",
    "print(t_scaled)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "s_scaled = sigmoid(t_scaled)\n",
    "print(s_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jorgenv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name, config=config)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "bert_model = bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([14, 768])\n",
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    headline = \"BREAKING: Musharraf to be impeached.\"\n",
    "    tokens = bert_tokenizer(headline, return_tensors='pt')\n",
    "    bert_model = bert_model.to(device)\n",
    "    output = bert_model(tokens.input_ids.to(device))\n",
    "    #print(output.last_hidden_state)\n",
    "    print(output.pooler_output.size())\n",
    "    latent_matrix = output.last_hidden_state[0]\n",
    "    print(latent_matrix.size())\n",
    "    mean_vector = torch.mean(latent_matrix, 0).to('cpu').detach().numpy()\n",
    "    mean_vector = mean_vector.reshape((1,-1))\n",
    "    print(mean_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    headline = \"BREAKING: Musharraf to be impeached.\"\n",
    "    tokens = bert_tokenizer(headline, return_tensors='pt')\n",
    "    bert_model = bert_model.to(device)\n",
    "    latent_matrix = output.last_hidden_state.to('cpu').detach().numpy()[0]\n",
    "    mean_vector = np.mean(latent_matrix, axis=0).reshape((1, latent_matrix.shape[1]))\n",
    "    print(mean_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2902, 0.3407, 0.9046, 0.0943],\n",
       "         [0.5204, 0.8343, 0.9265, 0.4997]],\n",
       "\n",
       "        [[0.0731, 0.9441, 0.8162, 0.1994],\n",
       "         [0.1855, 0.2908, 0.5922, 0.6943]],\n",
       "\n",
       "        [[0.4437, 0.5076, 0.0608, 0.3106],\n",
       "         [0.8169, 0.3862, 0.4164, 0.3761]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand((3, 2, 4))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4222],\n",
       "         [0.0664]],\n",
       "\n",
       "        [[0.6650],\n",
       "         [0.9036]],\n",
       "\n",
       "        [[0.1224],\n",
       "         [0.5757]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((3, 2, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1225, 0.1438, 0.3819, 0.0398],\n",
       "         [0.0346, 0.0554, 0.0615, 0.0332]],\n",
       "\n",
       "        [[0.0486, 0.6278, 0.5428, 0.1326],\n",
       "         [0.1677, 0.2628, 0.5351, 0.6273]],\n",
       "\n",
       "        [[0.0543, 0.0621, 0.0074, 0.0380],\n",
       "         [0.4703, 0.2223, 0.2397, 0.2165]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12252244, 0.14384354, 0.38192212, 0.03981346])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.multiply(0.4222, [0.2902, 0.3407, 0.9046, 0.0943])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8815d38e2f44888bf9d2d27291709bfd1a05b28bf990b1e1d952750508868489"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
